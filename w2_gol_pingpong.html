
<!DOCTYPE html>
<html lang="en">
	<head>
		<title>demo - Phong shader</title>
		<meta charset="utf-8">
		<style>
			body {
			  	margin: 0px;
				overflow: hidden;
			}
		</style>
	</head>
<body>

<div id="container"></div>

    <script src="js/three.js"></script>
  

    <script id="vertexShader" type="x-shader/x-vertex">
	uniform mat4 modelViewMatrix;
      	uniform mat4 projectionMatrix;

	attribute vec3 position;
	
    	void main() {
 		gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );
	}

    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">

		precision mediump float;

		uniform vec2 textureSize; //The width and height of our screen
		uniform sampler2D bufferTexture; //Our input texture
	
		bool compareColor(vec3 a, vec3 b) {
			bvec3 lt = lessThan(abs(a - b),  vec3(0.05, 0.05, 0.05));
			if (all(lt)) {
				return true;
			}
			return false;
		}

		void main() {

			vec2 pt = gl_FragCoord.xy; //for simple scenes, can also use gl_FragCoord instead of uv info, divide by texture size to get a value between 0.0 and 1.0
			vec4 C = texture2D( bufferTexture, vec2( pt.x/textureSize.x, pt.y/textureSize.y ) );

			float cx = pt.x/textureSize.x;

			float left = cx - 1.0/textureSize.x;
			if (left < 0.0) { left = 1.0; }
			float right = cx + 1.0/textureSize.x;
			if (right > 1.0) { right = 0.0; }

			float tleft = cx - 2.0*(1.0/textureSize.x);
			if (tleft < 0.0) { tleft = 1.0; }
			float tright = cx + 2.0*(1.0/textureSize.x);
			if (tright > 1.0) { tright = 0.0; }


			float cy = pt.y/textureSize.y;
			
			float down = cy - 1.0/textureSize.y;
			if (down < 0.0) { down = 1.0; }
			float up = cy + 1.0/textureSize.y;
			if (up > 1.0) { up = 0.0; }

			float tdown = cy - 2.0*(1.0/textureSize.y);
			if (tdown < 0.0) { tdown = 1.0; }
			float tup = cy + 2.0*(1.0/textureSize.y);
			if (tup > 1.0) { tup = 0.0; }
			const int surround_amt = 4;
			vec4 arr[surround_amt];

			arr[0] = texture2D( bufferTexture, vec2( cx   , up ));   //N
			arr[1] = texture2D( bufferTexture, vec2( right, cy ));   //E
			arr[2] = texture2D( bufferTexture, vec2( cx   , down )); //S
			arr[3] = texture2D( bufferTexture, vec2( left , cy ));   //W

//			arr[0] = texture2D( bufferTexture, vec2( cx   , up ));   //N
//			arr[1] = texture2D( bufferTexture, vec2( right, up ));   //NE
//			arr[2] = texture2D( bufferTexture, vec2( right, cy ));   //E
//			arr[3] = texture2D( bufferTexture, vec2( right, down )); //SE
//			arr[4] = texture2D( bufferTexture, vec2( cx   , down )); //S
//			arr[5] = texture2D( bufferTexture, vec2( left , down )); //SW
//			arr[6] = texture2D( bufferTexture, vec2( left , cy ));   //W
//			arr[7] = texture2D( bufferTexture, vec2( left , up ));   //NW
		//		     up up
//			arr[8] = texture2D( bufferTexture, vec2(  cx   , tup ));  
		//		     down  down
	//		arr[17] = texture2D( bufferTexture, vec2( cx,        tdown ));   
		//		     right right
		//	arr[21] = texture2D( bufferTexture, vec2( tright, cy ));   
		//		     left left
			//arr[13] = texture2D( bufferTexture, vec2( tleft,  cy ));   
		//		     down  down right 
			//arr[19] = texture2D( bufferTexture, vec2( right,     tdown ));
		//		     up up right
			//arr[9] = texture2D( bufferTexture, vec2(  right,     tup ));  
		//		     down  down right  right
			//arr[20] = texture2D( bufferTexture, vec2( tright, tdown ));
		//		     right right up
			//arr[22] = texture2D( bufferTexture, vec2( tright, up ));   
		//		     right right down
			//arr[23] = texture2D( bufferTexture, vec2( tright, down ));  
		//		     up up right right
			//arr[10] = texture2D( bufferTexture, vec2( tright, tup ));
		//		     down  down left
			//arr[18] = texture2D( bufferTexture, vec2( left,      tdown )); 
		//		     up up left
			//arr[11] = texture2D( bufferTexture, vec2( left,      tup ));   
		//		     up up left left
			//arr[12] = texture2D( bufferTexture, vec2( tleft,  tup )); 
		//		     left left up
			//arr[14] = texture2D( bufferTexture, vec2( tleft,  up ));   
		//		     left left down 
			//arr[15] = texture2D( bufferTexture, vec2( tleft,  down )); 
		//		     left left down  down
			//arr[16] = texture2D( bufferTexture, vec2( tleft,  tdown ));
			const int color_amt = 14;
			vec3 colors[color_amt];
			colors[0] = vec3(0.678, 0.847, 0.902);
			colors[1] = vec3(0.941, 0.502, 0.502);
			colors[2] = vec3(0.878, 1.000, 1.000);
			colors[3] = vec3(0.980, 0.980, 0.824);
			colors[4] = vec3(0.565, 0.933, 0.565);
			colors[5] = vec3(0.000, 1.000, 0.000);
			colors[6] = vec3(0.827, 0.827, 0.827);
			colors[7] = vec3(1.000, 0.714, 0.757);
			colors[8] = vec3(1.000, 0.627, 0.478);
			colors[9] = vec3(0.125, 0.698, 0.667);
			colors[10] = vec3(0.529, 0.808, 0.980);
			colors[11] = vec3(0.467, 0.533, 0.600);
			colors[12] = vec3(0.690, 0.769, 0.871);
			colors[13] = vec3(1.000, 1.000, 0.878);


			int cnts[color_amt];
			for(int i=0;i<surround_amt;i++){
				for (int j=0; j<color_amt; j++) {
					if (compareColor(arr[i].rgb, colors[j])) {
						cnts[j]++;
					}
				}
			}
						
			for (int i=0; i<color_amt; i++) {
				if (compareColor(C.rgb, colors[i])) { 
					if (i == color_amt-1) {
						if (cnts[0] >= 1) {
							//Any live cell with two or three live neighbours lives on to the next generation.
							gl_FragColor = vec4(colors[0], 1.0);
						} else {
							gl_FragColor = C;
						}
					} else {
						if (cnts[i+1] >= 1) {
							//Any live cell with two or three live neighbours lives on to the next generation.
							gl_FragColor = vec4(colors[i+1], 1.0);
						} else {
							gl_FragColor = C;
						}
					}
				} 
			}

		 }
	</script>



	<script>
		

var scene;
var camera;
var renderer;


var resX = 300;
var resY = 300;


var bufferScene;
var bufferMaterial;
var bufferObject;
var FBO_A, FBO_B;
var plane;
var fullScreenQuad;




scene_setup(); //initialize the Three.js scene

function scene_setup(){
	//This is the basic scene setup
	scene = new THREE.Scene();
	var width = window.innerWidth;
	var height = window.innerHeight;

	//orthographic camera can be used for 2D
	camera = new THREE.OrthographicCamera( width / -2, width / 2, height / 2, height / -2, 0.1, 1000 );
	camera.position.z = 0.2;

	renderer = new THREE.WebGLRenderer();
	renderer.setSize( window.innerWidth, window.innerHeight );
	document.body.appendChild( renderer.domElement );
}


FBO_setup();

function FBO_setup(){
	//Create off-screen buffer scene
	bufferScene = new THREE.Scene();
	
	//Create 2 buffer textures
	//FBO_A = new THREE.WebGLRenderTarget( resX, resY );
	//FBO_B = new THREE.WebGLRenderTarget( resX, resY ); 
	FBO_A = new THREE.WebGLRenderTarget( resX, resY, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter});
	FBO_B = new THREE.WebGLRenderTarget( resX, resY, { minFilter: THREE.LinearFilter, magFilter: THREE.NearestFilter} );


	
	//Begin by passing an initial "seed" texture to shader, containing randomly placed cells
	var dataTexture = createDataTexture();

	bufferMaterial = new THREE.RawShaderMaterial( {
		uniforms: {
			bufferTexture: { type: "t", value: dataTexture },
			textureSize : {type: "v2", value: new THREE.Vector2( resX, resY )}  //shader doesn't have access to these global variables, so pass in the resolution
		},
		vertexShader: document.getElementById( 'vertexShader' ).innerHTML,
		fragmentShader: document.getElementById( 'fragmentShader' ).innerHTML
	} );

	//we can use a Three.js Plane Geometry along with the orthographic camera to create a "full screen quad"
	plane = new THREE.PlaneBufferGeometry( window.innerWidth, window.innerHeight )

	bufferObject = new THREE.Mesh( plane, bufferMaterial );
	bufferScene.add(bufferObject);


	//Draw textureB to screen 
	fullScreenQuad = new THREE.Mesh( plane, new THREE.MeshBasicMaterial() );
	scene.add(fullScreenQuad);
}



render();

function render() {

	requestAnimationFrame( render );

	
	//Draw to the active offscreen buffer (whatever is stored in FBO_B), that is the output of this rendering pass will be stored in the texture associated with FBO_B
	renderer.render(bufferScene, camera, FBO_B);
	
	//grab that texture and map it to the full screen quad
	fullScreenQuad.material.map = FBO_B.texture;

	//Then draw the full sceen quad to the on screen buffer, ie, the display
	renderer.render( scene, camera );


	//Now prepare for the next cycle by swapping FBO_A and FBO_B, so that the previous frame's *output* becomes the next frame's *input*
	var t = FBO_A;
	FBO_A = FBO_B;
	FBO_B = t;
	bufferMaterial.uniforms.bufferTexture.value = FBO_A.texture;
}




function createDataTexture() {

	// create a buffer with color data

	var size = resX * resY;
	var data = new Uint8Array( 4 * size );

	let color_amt = 14;
	let interval = 1.0/color_amt;
	let colors = [];
	colors[0] = [0.678, 0.847, 0.902];
	colors[1] = [0.941, 0.502, 0.502];
	colors[2] = [0.878, 1.000, 1.000];
	colors[3] = [0.980, 0.980, 0.824];
	colors[4] = [0.565, 0.933, 0.565];
	colors[5] = [0.000, 1.000, 0.000];
	colors[6] = [0.827, 0.827, 0.827];
	colors[7] = [1.000, 0.714, 0.757];
	colors[8] = [1.000, 0.627, 0.478];
	colors[9] = [0.125, 0.698, 0.667];
	colors[10] = [0.529, 0.808, 0.980];
	colors[11] = [0.467, 0.533, 0.600];
	colors[12] = [0.690, 0.769, 0.871];
	colors[13] = [1.000, 1.000, 0.878];

	console.log(colors[0]);
	for ( var i = 0; i < size; i++ ) {

		var stride = i * 4;
		let r = Math.floor(14.0 * Math.random());
		data[stride] = colors[r][0]*255;
		data[stride+1] = colors[r][1]*255;
		data[stride+2] = colors[r][2]*255;
		data[stride+3] = 255;

	}


	// used the buffer to create a DataTexture

	console.log(data);
	var texture = new THREE.DataTexture( data, resX, resY, THREE.RGBAFormat );
	
	texture.needsUpdate = true; // just a weird thing that Three.js wants you to do after you set the data for the texture

	return texture;

}
	</script>

</body>
</html>

